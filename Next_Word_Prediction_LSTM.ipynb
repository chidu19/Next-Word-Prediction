{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chidu19/Next-Word-Prediction/blob/main/Next_Word_Prediction_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NorjvIOC2NEg"
      },
      "source": [
        "# 📘 Next Word Prediction using LSTM\n",
        "\n",
        "This project is inspired by the LGM Data Science Internship assignment. We build a simplified version of a GPT-like model that predicts the next word given a few input words."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4pfgFtHesgB",
        "outputId": "24c19e89-3293-47a8-9aa1-417bf72097bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZRJA8Os2NEi"
      },
      "source": [
        "## 📥 Step 1: Load and Preprocess Text\n",
        "We start by reading the eBook (`book.txt`) and cleaning it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WBCSEAmJ2NEj",
        "outputId": "dc553cde-a474-4e35-b42d-1c534b9b74d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample words: ['project', 'gutenbergs', 'the', 'adventures', 'of', 'sherlock', 'holmes', 'by', 'arthur', 'conan', 'doyle', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere']\n",
            "Total words: 107430\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Your sample or custom text\n",
        "text = \"\"\"\n",
        "Once upon a time there was a king who ruled a vast kingdom.\n",
        "The people of the kingdom were happy and prosperous.\n",
        "One day, a stranger arrived in the kingdom.\n",
        "He brought stories of a distant land full of magic and mystery.\n",
        "\"\"\"\n",
        "\n",
        "# Clean and split text\n",
        "text = text.lower().replace(\"\\n\", \" \")\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "\n",
        "with open('book.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "import re\n",
        "words = re.sub(r\"[^a-zA-Z\\s]\", \"\", text).split()\n",
        "\n",
        "print(f\"Sample words: {words[:20]}\")\n",
        "print(f\"Total words: {len(words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J_ryAEv2NEk"
      },
      "source": [
        "## 📊 Step 2: EDA - Word Frequency & Bigrams\n",
        "We analyze word frequency and common bigrams."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zAogqYD62NEl",
        "outputId": "82951d4f-e106-48bc-d448-bc7c847c219c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common words: [('the', 5805), ('and', 3070), ('i', 2995), ('of', 2778), ('to', 2762), ('a', 2683), ('in', 1818), ('that', 1750), ('it', 1710), ('you', 1545)]\n",
            "Least common words: [('michael', 1), ('hart', 1), ('originator', 1), ('network', 1), ('necessarily', 1), ('edition', 1), ('pg', 1), ('includes', 1), ('subscribe', 1), ('newsletter', 1)]\n",
            "\n",
            "Common bigrams:\n",
            "('of', 'the') -> 743\n",
            "('in', 'the') -> 522\n",
            "('it', 'is') -> 336\n",
            "('to', 'the') -> 319\n",
            "('i', 'have') -> 299\n",
            "('it', 'was') -> 276\n",
            "('that', 'i') -> 256\n",
            "('at', 'the') -> 240\n",
            "('and', 'i') -> 214\n",
            "('and', 'the') -> 203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from nltk import bigrams\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "word_freq = Counter(words)\n",
        "print(\"Most common words:\", word_freq.most_common(10))\n",
        "print(\"Least common words:\", word_freq.most_common()[-10:])\n",
        "\n",
        "bi_freq = Counter(bigrams(words))\n",
        "print(\"\\nCommon bigrams:\")\n",
        "for pair, count in bi_freq.most_common(10):\n",
        "    print(f\"{pair} -> {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAFa_fGs2NEm"
      },
      "source": [
        "## 🧠 Step 3: Prepare Sequences\n",
        "We create a sliding window of 5 words as input and the 6th word as the label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bmtmi1oC2NEm",
        "outputId": "d4f7faf7-2791-4276-d066-fade612bd881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input-output pair:\n",
            "['project', 'gutenbergs', 'the', 'adventures', 'of'] -> sherlock\n"
          ]
        }
      ],
      "source": [
        "SEQUENCE_LENGTH = 5\n",
        "input_sequences = []\n",
        "output_words = []\n",
        "\n",
        "for i in range(len(words) - SEQUENCE_LENGTH):\n",
        "    input_sequences.append(words[i:i + SEQUENCE_LENGTH])\n",
        "    output_words.append(words[i + SEQUENCE_LENGTH])\n",
        "\n",
        "print(\"Sample input-output pair:\")\n",
        "print(input_sequences[0], \"->\", output_words[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNOTxpH12NEn"
      },
      "source": [
        "## 🔤 Step 4: Tokenization & One-Hot Encoding\n",
        "We map words to indices and one-hot encode them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "K1YME-8s2NEn",
        "outputId": "b6701ca7-3c5e-4500-bdb5-041717527fe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (107425, 5), y shape: (107425, 8601)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(words)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Integer encode input sequences\n",
        "X_int = np.array([[tokenizer.word_index[word] for word in seq] for seq in input_sequences])\n",
        "y_int = np.array([tokenizer.word_index[word] for word in output_words])\n",
        "\n",
        "# Pad sequences (though they should already be fixed-length)\n",
        "X = X_int\n",
        "y = to_categorical(y_int, num_classes=vocab_size)\n",
        "\n",
        "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCqBU6OS2NEo"
      },
      "source": [
        "## 🏗️ Step 5: Build and Train LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LJc-YO4W2NEo",
        "outputId": "ecf17d01-7b03-420e-cc23-932554befe18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=64, input_length=SEQUENCE_LENGTH),\n",
        "    LSTM(128),\n",
        "    Dropout(0.2),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X9puKq6fYVM",
        "outputId": "e66e3f0d-aa7c-4237-f692-b3d54c596f12"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 68ms/step - accuracy: 0.0503 - loss: 7.0069 - val_accuracy: 0.0643 - val_loss: 6.8449\n",
            "Epoch 2/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 65ms/step - accuracy: 0.0677 - loss: 6.1861 - val_accuracy: 0.0823 - val_loss: 6.6431\n",
            "Epoch 3/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 67ms/step - accuracy: 0.0929 - loss: 5.8396 - val_accuracy: 0.1019 - val_loss: 6.5519\n",
            "Epoch 4/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 67ms/step - accuracy: 0.1156 - loss: 5.5599 - val_accuracy: 0.1109 - val_loss: 6.5544\n",
            "Epoch 5/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 65ms/step - accuracy: 0.1308 - loss: 5.3423 - val_accuracy: 0.1169 - val_loss: 6.5909\n",
            "Epoch 6/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 64ms/step - accuracy: 0.1409 - loss: 5.1424 - val_accuracy: 0.1205 - val_loss: 6.6472\n",
            "Epoch 7/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 66ms/step - accuracy: 0.1477 - loss: 4.9874 - val_accuracy: 0.1205 - val_loss: 6.7085\n",
            "Epoch 8/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 64ms/step - accuracy: 0.1542 - loss: 4.8326 - val_accuracy: 0.1208 - val_loss: 6.7785\n",
            "Epoch 9/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 67ms/step - accuracy: 0.1640 - loss: 4.6940 - val_accuracy: 0.1238 - val_loss: 6.8492\n",
            "Epoch 10/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 66ms/step - accuracy: 0.1753 - loss: 4.5545 - val_accuracy: 0.1244 - val_loss: 6.9352\n",
            "Epoch 11/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 70ms/step - accuracy: 0.1818 - loss: 4.4355 - val_accuracy: 0.1231 - val_loss: 6.9978\n",
            "Epoch 12/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 65ms/step - accuracy: 0.1922 - loss: 4.2964 - val_accuracy: 0.1242 - val_loss: 7.0672\n",
            "Epoch 13/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 70ms/step - accuracy: 0.2028 - loss: 4.1730 - val_accuracy: 0.1239 - val_loss: 7.1542\n",
            "Epoch 14/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 66ms/step - accuracy: 0.2143 - loss: 4.0617 - val_accuracy: 0.1249 - val_loss: 7.2424\n",
            "Epoch 15/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 70ms/step - accuracy: 0.2283 - loss: 3.9405 - val_accuracy: 0.1230 - val_loss: 7.3202\n",
            "Epoch 16/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 66ms/step - accuracy: 0.2380 - loss: 3.8346 - val_accuracy: 0.1225 - val_loss: 7.3952\n",
            "Epoch 17/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 66ms/step - accuracy: 0.2548 - loss: 3.7386 - val_accuracy: 0.1221 - val_loss: 7.4770\n",
            "Epoch 18/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 67ms/step - accuracy: 0.2657 - loss: 3.6425 - val_accuracy: 0.1205 - val_loss: 7.5506\n",
            "Epoch 19/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 66ms/step - accuracy: 0.2817 - loss: 3.5268 - val_accuracy: 0.1203 - val_loss: 7.6345\n",
            "Epoch 20/20\n",
            "\u001b[1m756/756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 67ms/step - accuracy: 0.2963 - loss: 3.4383 - val_accuracy: 0.1181 - val_loss: 7.7034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x791247128290>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVKMAmI02NEo"
      },
      "source": [
        "## 🔮 Step 6: Predict the Next Word\n",
        "We build a prediction function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kNoWh2292NEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b33859-fbf0-4da0-f31d-ce9d3bcec7f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sidealley\n"
          ]
        }
      ],
      "source": [
        "def predict_next_word(seed_text):\n",
        "    input_words = seed_text.lower().split()\n",
        "    if len(input_words) != SEQUENCE_LENGTH:\n",
        "        raise ValueError(f\"Expected {SEQUENCE_LENGTH} words.\")\n",
        "\n",
        "    # Convert words to indices\n",
        "    input_seq = [word_to_index.get(w, 0) for w in input_words]\n",
        "\n",
        "    # No one-hot encoding here — just word indices\n",
        "    input_seq_encoded = np.array([input_seq])  # Shape: (1, SEQUENCE_LENGTH)\n",
        "\n",
        "    # Predict next word\n",
        "    prediction = model.predict(input_seq_encoded, verbose=0)\n",
        "\n",
        "    # Get index of most probable word\n",
        "    predicted_index = np.argmax(prediction)\n",
        "\n",
        "    # Convert index back to word\n",
        "    return index_to_word[predicted_index]\n",
        "\n",
        "# Example usage\n",
        "print(predict_next_word(\"sherlock holmes was very good\"))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}